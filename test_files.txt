
================================================================================
FILE: tests/conftests.py
================================================================================




================================================================================
FILE: tests/data/bad.py
================================================================================




def foo(:


================================================================================
FILE: tests/data/basic.py
================================================================================

class Test:
    pass


def foo():
    pass



================================================================================
FILE: tests/data/docstring_examples.py
================================================================================

def foo():
    """Docstring de foo"""
    # Comentario entre docstring y c√≥digo
    pass


class Bar:
    """Docstring de clase"""

    def baz(self):
        """Docstring de m√©todo"""
        pass



================================================================================
FILE: tests/data/edge_cases.py
================================================================================

# Este es un comentario normal
a = "# Esto no es un comentario"


# TODO: pendiente de implementar
def foo():
    pass


# FIXME: caso raro

"""
Esto es un docstring
# Esto no es un comentario real
"""

# Otro comentario



================================================================================
FILE: tests/data/edge_cases_blanklines.py
================================================================================

# Primeras dos l√≠neas en blanco


def bar():
    pass

    # L√≠nea en blanco al final



================================================================================
FILE: tests/data/edge_cases_comments.py
================================================================================

# Este es un comentario con acento: √°√©√≠√≥√∫
print("No es comentario # pero parece")  # Comentario con emoji üòä
x = "# Esto tampoco es comentario"
y = 42  # TODO: tarea pendiente Œª


def foo():
    """Este docstring contiene # pero no es comentario"""
    pass


# L√≠nea s√≥lo con comentario
#
# Comentario sin espacio tras hash
#    Comentario con indentaci√≥n
# FIXME ‚Äî revisar s√≠mbolos matem√°ticos: ‚àë, œÄ, ‚àö



================================================================================
FILE: tests/test_phase_2.py
================================================================================

import json
import subprocess
from pathlib import Path
from typing import Any

REPO_FIXTURE = Path(__file__).parent / "data"


def _run(extra_args: list[str]) -> str:
    cmd = [
        "repogpt",
        *extra_args,
        "--include-tests",  # asegurar que Directorios 'tests' no se excluyan
        str(REPO_FIXTURE),
    ]
    proc = subprocess.run(cmd, capture_output=True, text=True, check=True)
    return proc.stdout


def _json_lines(stdout: str) -> list[dict[str, Any]]:
    return [json.loads(line) for line in stdout.strip().split("\n") if line.strip()]


def test_languages_filter() -> None:
    out = _run(
        ["--languages", "py", "--stdout", "--format", "ndjson", "--flatten", "file"]
    )
    objs = _json_lines(out)
    assert objs, "expected at least one object"
    assert all(o["lang"] == "py" for o in objs)


def test_ndjson_file_lines() -> None:
    out = _run(["--stdout", "--format", "ndjson", "--flatten", "file"])
    objs = _json_lines(out)
    py_files = set(REPO_FIXTURE.glob("*.py"))
    md_files = set(REPO_FIXTURE.glob("*.md"))
    expected = [p for p in (py_files | md_files) if p.name != "bad.py"]
    assert len(objs) == len(expected)



================================================================================
FILE: tests/test_phase_3.py
================================================================================

import subprocess
from pathlib import Path

REPO = Path(__file__).parent / "data"
BAD_FILE = REPO / "bad.py"


def _run(args: list[str]) -> subprocess.CompletedProcess[str]:
    return subprocess.run(
        ["repogpt", *args, str(REPO)],
        capture_output=True,
        text=True,
    )


def test_fail_fast() -> None:
    proc = _run(["--fail-fast", "--stdout", "--include-tests"])
    assert proc.returncode == 1
    assert "aborting ‚Äî fail-fast" in proc.stderr


def test_debug_logs() -> None:
    proc = _run(["--stdout", "--log-level", "DEBUG", "--include-tests"])
    assert proc.returncode == 0
    assert "starting run" in proc.stderr


# # cleanup
# BAD_FILE.unlink(missing_ok=True)



================================================================================
FILE: tests/unit/adapters/collector/test_simple_collector.py
================================================================================

from pathlib import Path
import pytest

from repogpt.adapters.collector.simple_collector import SimpleCollector
from repogpt.models import AnalysisConf


def test_collect_ignores_git_files(tmp_path: Path) -> None:
    # Preparo un repo con .git, .gitignore y archivos .py / .pyc
    git_dir = tmp_path / ".git"
    git_dir.mkdir()
    (git_dir / "config").write_text("test")
    (tmp_path / ".gitignore").write_text("*.pyc\n__pycache__/\n")
    (tmp_path / "main.py").write_text("print('test')")
    (tmp_path / "test.pyc").write_text("test")
    (tmp_path / "__pycache__").mkdir()
    (tmp_path / "__pycache__" / "test.pyc").write_text("test")

    collector = SimpleCollector()
    conf = AnalysisConf(repo_path=tmp_path)
    result = collector.collect(conf)

    assert len(result.files) == 1
    assert result.files[0].name == "main.py"


def test_collect_respects_repogptignore(tmp_path: Path) -> None:
    # Ahora usamos .repogptignore en lugar de argumentos al constructor
    (tmp_path / ".repogptignore").write_text("*.py\n__pycache__/\n")
    (tmp_path / "keep.py").write_text("print('ok')")
    (tmp_path / "skip.py").write_text("print('no')")
    collector = SimpleCollector()
    conf = AnalysisConf(repo_path=tmp_path)
    result = collector.collect(conf)

    assert len(result.files) == 0


def test_collect_includes_tests_when_requested(tmp_path: Path) -> None:
    (tmp_path / "foo.py").write_text("x=1")
    (tmp_path / "test_foo.py").write_text("x=2")

    collector = SimpleCollector()
    conf = AnalysisConf(repo_path=tmp_path, include_tests=True)
    result = collector.collect(conf)

    names = {f.name for f in result.files}
    assert names == {"foo.py", "test_foo.py"}


def test_collect_excludes_tests_by_default(tmp_path: Path) -> None:
    (tmp_path / "foo.py").write_text("x=1")
    (tmp_path / "test_foo.py").write_text("x=2")

    collector = SimpleCollector()
    conf = AnalysisConf(repo_path=tmp_path, include_tests=False)
    result = collector.collect(conf)

    names = {f.name for f in result.files}
    assert names == {"foo.py"}


def test_collect_empty_directory_returns_empty(tmp_path: Path) -> None:
    collector = SimpleCollector()
    conf = AnalysisConf(repo_path=tmp_path)
    result = collector.collect(conf)
    assert result.files == []


def test_collect_nonexistent_directory_raises(tmp_path: Path) -> None:
    collector = SimpleCollector()
    conf = AnalysisConf(repo_path=Path("no-such-dir"))
    with pytest.raises(FileNotFoundError):
        collector.collect(conf)


def test_collect_file_instead_of_directory_raises(tmp_path: Path) -> None:
    file = tmp_path / "solo.py"
    file.write_text("x=1")
    collector = SimpleCollector()
    conf = AnalysisConf(repo_path=file)
    with pytest.raises(NotADirectoryError):
        collector.collect(conf)



================================================================================
FILE: tests/unit/adapters/parsers/test_md_parser.py
================================================================================

# import os
# from pathlib import Path
# from repogpt.adapters.parser.md_parser import MarkdownParser
# from repogpt.models import ParserConf, ParserInput

# DATA_DIR = os.path.join(os.path.dirname(__file__), "../../../data")

# def load_path(filename):
#     return Path(os.path.join(DATA_DIR, filename))

# def test_basic_md_headings():
#     parser = MarkdownParser(ParserConf(language="markdown"))
#     input_ = ParserInput(file_path=load_path("basic.md"), file_info={})
#     result = parser.parse(input_)
#     assert [h["level"] for h in result.headings] == [1, 2]
#     assert [h["title"] for h in result.headings] == ["T√≠tulo 1", "Subt√≠tulo"]
#     assert result.links == []

#     assert result.code_blocks == 0

# def test_with_comments_md_comments_and_todos_fixmes():
#     parser = MarkdownParser(ParserConf(language="markdown"))
#     input_ = ParserInput(file_path=load_path("with_comments.md"), file_info={})
#     result = parser.parse(input_)
#     # Los comentarios extra√≠dos deben coincidir con los del archivo
#     assert any(
#         comment in result.todos_fixmes
#         for comment in [
#             "Este es un comentario en markdown",
#             "TODO: Completar secci√≥n",
#             "FIXME: Revisar formato"
#         ]
#     )
#     # Testea tambi√©n single_comments_count y blank_lines
#     assert result.single_comments_count == 3
#     # TODO y FIXME separados:
#     assert "TODO: Completar secci√≥n" in result.todos_fixmes
#     assert "FIXME: Revisar formato" in result.todos_fixmes

# def test_with_comments_md_headings_links_codeblocks():
#     parser = MarkdownParser(ParserConf(language="markdown"))
#     input_ = ParserInput(file_path=load_path("with_comments.md"), file_info={})
#     result = parser.parse(input_)

#     assert any(h["level"] == 1 and h["title"] == "T√≠tulo" for h in result.headings)
#     assert result.links == []
#     assert result.code_blocks == 1

# def test_edge_cases_md():
#     parser = MarkdownParser(ParserConf(language="markdown"))
#     input_ = ParserInput(file_path=load_path("edge_cases.md"), file_info={})
#     result = parser.parse(input_)
#     # Headings y links
#     assert result.headings == []

#     assert result.links == [{"text": "OpenAI", "url": "https://openai.com"}]
#     # Code blocks: hay un bloque ```

#     assert result.code_blocks == 1
#     # La preview incluye el comienzo del texto
#     assert "üéâ" in result.content_preview
#     assert result.blank_lines >= 0  # Seg√∫n el archivo

# def test_edge_cases_md_in_line_comment():
#     parser = MarkdownParser(ParserConf(language="markdown"))
#     input_ = ParserInput(file_path=load_path("edge_cases.md"), file_info={})
#     result = parser.parse(input_)
#     # Busca el comentario en l√≠nea (no es HTML, as√≠ que seg√∫n el extractor,
#     # puede que no lo detecte)
#     assert "Comentario en l√≠nea" not in result.todos_fixmes  # Solo se detectan <!-- ... -->

# def test_blank_lines_basic_md():
#     parser = MarkdownParser(ParserConf(language="markdown"))
#     input_ = ParserInput(file_path=load_path("basic.md"), file_info={})
#     result = parser.parse(input_)
#     assert result.blank_lines >= 1  # Seg√∫n el contenido

# def test_no_comments_basic_md():
#     parser = MarkdownParser(ParserConf(language="markdown"))
#     input_ = ParserInput(file_path=load_path("basic.md"), file_info={})
#     result = parser.parse(input_)
#     assert result.single_comments_count == 0
#     assert result.comments_count == 0



================================================================================
FILE: tests/unit/adapters/parsers/test_py_parser.py
================================================================================

# tests/unit/adapters/parsers/test_py_parser.py

import os
from pathlib import Path

from repogpt.adapters.parser.py_parser import PythonParser
from repogpt.models import ParserInput
from repogpt.utils.tree_utils import (
    all_comments,
    all_docstrings,
    all_tags,
    flatten_tree,
)

DATA_DIR = os.path.join(os.path.dirname(__file__), "../../../data")


def load_path(filename: str) -> Path:
    return Path(os.path.join(DATA_DIR, filename))


def test_basic_py_structure() -> None:
    parser = PythonParser()
    input_ = ParserInput(file_path=load_path("basic.py"), file_info={})
    root = parser.parse(input_)

    assert root.type == "Module"
    types = [child.type for child in root.children]
    assert set(types) == {"Class", "Function"}
    names = [child.name for child in root.children]
    assert "Test" in names
    assert "foo" in names

    # Cambia aqu√≠:
    comments = all_comments(root)
    assert comments == []
    docstrings = all_docstrings(root)
    assert docstrings == []


def test_docstring_examples() -> None:
    parser = PythonParser()
    input_ = ParserInput(file_path=load_path("docstring_examples.py"), file_info={})
    root = parser.parse(input_)

    # Buscar nodos
    funcs = [n for n in flatten_tree(root) if n["type"] == "Function"]
    classes = [n for n in flatten_tree(root) if n["type"] == "Class"]

    # Funci√≥n foo tiene docstring
    foo = [f for f in funcs if f["name"] == "foo"][0]
    assert "Docstring de foo" in foo["docstring"]

    # Clase Bar y m√©todo baz
    bar = [c for c in classes if c["name"] == "Bar"][0]
    assert "Docstring de clase" in bar["docstring"]
    baz = [f for f in funcs if f["name"] == "baz"][0]
    assert "Docstring de m√©todo" in baz["docstring"]

    # Extraer todos los comentarios
    comments = all_comments(root)
    texts = [c["text"] for c in comments]
    assert any("Comentario entre docstring y c√≥digo" in t for t in texts)


def test_edge_cases_py_comments_and_docstrings() -> None:
    parser = PythonParser()
    input_ = ParserInput(file_path=load_path("edge_cases.py"), file_info={})
    root = parser.parse(input_)

    # Todos los comentarios recogidos (deben estar en cualquier nodo)
    comments = all_comments(root)
    texts = [c["text"] for c in comments]
    n_todos = sum([1 if "TODO" in t else 0 for t in texts])
    n_fixme = sum([1 if "FIXME" in t else 0 for t in texts])
    print(texts)
    assert "Este es un comentario normal" in texts
    assert n_todos == 1
    assert n_fixme == 1

    # Los docstrings solo existen si hay funciones/clases/m√≥dulo con ellos
    docstrings = all_docstrings(root)
    # En este archivo, no deber√≠a haber docstrings, as√≠ que:
    assert docstrings == []  # o len(docstrings) == 0

    # Test tags (si tu parser a√±ade TODO/FIXME como tags)
    tags = all_tags(root)
    print(tags)
    assert "TODO" in tags or n_todos == 1
    assert "FIXME" in tags or n_fixme == 1


def test_edge_cases_blanklines_py() -> None:
    parser = PythonParser()
    input_ = ParserInput(file_path=load_path("edge_cases_blanklines.py"), file_info={})
    root = parser.parse(input_)
    # Chequea el conteo de l√≠neas en blanco (se almacena en root.metrics)
    blank_lines = root.metrics.get("blank_lines", 0)  # Provide default value of 0
    assert blank_lines == 3  # seg√∫n el archivo, ajusta si cambia el fixture

    loc = root.metrics.get("lines_of_code", 0)  # Provide default value of 0
    assert loc > 0


def test_edge_cases_comments_py() -> None:
    parser = PythonParser()
    input_ = ParserInput(file_path=load_path("edge_cases_comments.py"), file_info={})
    root = parser.parse(input_)

    comments = all_comments(root)
    texts = [c["text"] for c in comments]
    assert any("√°√©√≠√≥√∫" in t for t in texts)
    assert any("üòä" in t for t in texts)
    assert any("tarea pendiente Œª" in t for t in texts)
    assert any("Comentario sin espacio" in t for t in texts)
    assert any("indentaci√≥n" in t for t in texts)
    assert any("s√≠mbolos matem√°ticos" in t for t in texts)



================================================================================
FILE: tests/unit/adapters/pipeline/test_simple_pipeline.py
================================================================================

from pathlib import Path
import uuid
from typing import TypeVar

from repogpt.adapters.pipeline.simple_pipeline import SimplePipeline, Processor
from repogpt.models import AnalysisConf, CodeNode, ParserInput

T = TypeVar("T", bound=CodeNode)


class MockParser:
    def parse(self, input: ParserInput) -> CodeNode:
        # Devuelve siempre un nodo ra√≠z muy b√°sico
        return CodeNode(
            id=str(uuid.uuid4()),
            type="module",
            name="test",
            language="py",
            path=str(input.file_path),
            start_line=1,
            end_line=1,
            children=[],
        )


class MockProcessor(Processor[T]):
    def __call__(self, node: T) -> T:
        node.name = "processed"
        return node


def test_process_success(tmp_path: Path) -> None:
    # Creo un archivo de prueba
    fp = tmp_path / "test.py"
    contenido = "print('hola')"
    fp.write_text(contenido, encoding="utf-8")

    parser = MockParser()
    processor: Processor[CodeNode] = MockProcessor[CodeNode]()
    pipeline = SimplePipeline(parsers={"py": parser}, processors={"py": processor})
    conf = AnalysisConf(repo_path=tmp_path)

    result = pipeline.process(fp, conf)

    assert result.path == fp
    assert result.language == "py"
    assert result.file_info["size"] == len(contenido)
    assert isinstance(result.file_info.get("sha256"), str)
    assert result.root is not None
    assert result.root.name == "processed"
    assert result.error is None


def test_process_no_parser(tmp_path: Path) -> None:
    fp = tmp_path / "test.py"
    fp.write_text("x=1", encoding="utf-8")

    pipeline = SimplePipeline(parsers={}, processors={})
    conf = AnalysisConf(repo_path=tmp_path)
    result = pipeline.process(fp, conf)

    assert result.path == fp
    assert result.language == "py"
    assert result.root is None
    assert result.error == "no parser"


def test_process_parser_error(tmp_path: Path) -> None:
    class ErrorParser:
        def parse(self, input: ParserInput) -> CodeNode:
            raise ValueError("test error")

    fp = tmp_path / "boom.py"
    fp.write_text("x=1", encoding="utf-8")

    pipeline = SimplePipeline(parsers={"py": ErrorParser()}, processors={})
    conf = AnalysisConf(repo_path=tmp_path)
    result = pipeline.process(fp, conf)

    assert result.path == fp
    assert result.language == "py"
    assert result.root is None
    assert result.error is not None
    assert "test error" in result.error


def test_process_no_processors(tmp_path: Path) -> None:
    fp = tmp_path / "plain.py"
    fp.write_text("x=2", encoding="utf-8")

    parser = MockParser()
    pipeline = SimplePipeline(parsers={"py": parser}, processors={})
    conf = AnalysisConf(repo_path=tmp_path)
    result = pipeline.process(fp, conf)

    assert result.root is not None
    assert result.root.name == "test"
    assert result.error is None



================================================================================
FILE: tests/unit/adapters/publisher/test_simple_publisher.py
================================================================================

import json
from pathlib import Path
from typing import Any

from repogpt.adapters.publisher.simple_publisher import SimplePublisher
from repogpt.models import AnalysisConf, CodeNode, PipelineResult


def test_publish_json(tmp_path: Path) -> None:
    output = tmp_path / "out.json"
    conf = AnalysisConf(
        repo_path=tmp_path,
        output=output,
        output_format="json",
        flatten_kind="node",
    )

    node = CodeNode(
        id="1",
        type="module",
        name="test",
        language="py",
        path="test.py",
        start_line=1,
        end_line=1,
        children=[],
    )
    result = PipelineResult(
        path=Path("test.py"),
        language="py",
        root=node,
        file_info={"size": 100},
    )

    publisher = SimplePublisher()
    publisher.publish([result], conf)

    data = json.loads(output.read_text(encoding="utf-8"))
    assert len(data) == 1
    assert data[0]["type"] == "module"
    assert data[0]["name"] == "test"
    assert data[0]["path"] == "test.py"
    assert data[0]["lang"] == "py"
    assert data[0]["size"] == 100


def test_publish_ndjson(tmp_path: Path) -> None:
    output = tmp_path / "out.ndjson"
    conf = AnalysisConf(
        repo_path=tmp_path,
        output=output,
        output_format="ndjson",
        flatten_kind="node",
    )

    node = CodeNode(
        id="1",
        type="module",
        name="test",
        language="py",
        path="test.py",
        start_line=1,
        end_line=1,
        children=[],
    )
    result = PipelineResult(
        path=Path("test.py"),
        language="py",
        root=node,
        file_info={"size": 100},
    )

    publisher = SimplePublisher()
    publisher.publish([result], conf)

    lines = output.read_text(encoding="utf-8").splitlines()
    data = [json.loads(line) for line in lines if line.strip()]
    assert len(data) == 1
    assert data[0]["type"] == "module"
    assert data[0]["name"] == "test"
    assert data[0]["path"] == "test.py"
    assert data[0]["lang"] == "py"
    assert data[0]["size"] == 100


def test_publish_stdout(capsys: Any) -> None:
    conf = AnalysisConf(
        repo_path=Path.cwd(),
        to_stdout=True,
        output_format="json",
        flatten_kind="node",
    )
    node = CodeNode(
        id="1",
        type="module",
        name="test",
        language="py",
        path="test.py",
        start_line=1,
        end_line=1,
        children=[],
    )
    result = PipelineResult(
        path=Path("test.py"),
        language="py",
        root=node,
        file_info={"size": 100},
    )

    publisher = SimplePublisher()
    publisher.publish([result], conf)

    out = capsys.readouterr().out
    data = json.loads(out)
    assert len(data) == 1
    assert data[0]["type"] == "module"
    assert data[0]["name"] == "test"
    assert data[0]["path"] == "test.py"
    assert data[0]["lang"] == "py"
    assert data[0]["size"] == 100


def test_publish_with_error(tmp_path: Path) -> None:
    output = tmp_path / "out.json"
    conf = AnalysisConf(
        repo_path=tmp_path,
        output=output,
        output_format="json",
        flatten_kind="node",
    )
    result = PipelineResult(
        path=Path("test.py"),
        language="py",
        root=None,
        error="err!",
        file_info={"size": 100},
    )

    publisher = SimplePublisher()
    publisher.publish([result], conf)

    data = json.loads(output.read_text(encoding="utf-8"))
    assert data == []


def test_publish_empty_results(tmp_path: Path) -> None:
    output = tmp_path / "out.json"
    conf = AnalysisConf(
        repo_path=tmp_path,
        output=output,
        output_format="json",
        flatten_kind="node",
    )
    publisher = SimplePublisher()
    publisher.publish([], conf)

    data = json.loads(output.read_text(encoding="utf-8"))
    assert data == []



================================================================================
FILE: tests/unit/models.py
================================================================================




================================================================================
FILE: tests/unit/utils/test_text_processing.py
================================================================================

import os

from repogpt.utils.text_processing import (
    count_blank_lines,
    extract_comments,
    extract_todos_fixmes,
)

DATA_DIR = os.path.join(os.path.dirname(__file__), "../../data")


def load_file(name: str) -> str:
    with open(os.path.join(DATA_DIR, name), encoding="utf-8") as f:
        return f.read()


# ---------- BASIC PYTHON ----------
def test_blank_lines_basic_py() -> None:
    text = load_file("basic.py")
    assert count_blank_lines(text) == 2


def test_comments_basic_py() -> None:
    text = load_file("basic.py")
    comments = extract_comments(text, language="python")
    assert comments == []


# ---------- WITH COMMENTS MARKDOWN ----------
def test_comments_with_comments_md() -> None:
    text = load_file("with_comments.md")
    comments = extract_comments(text, language="markdown")
    texts = [c["text"] for c in comments]
    assert texts == [
        "Este es un comentario en markdown",
        "TODO: Completar secci√≥n",
        "FIXME: Revisar formato",
    ]
    todos, fixmes = extract_todos_fixmes(comments)
    todos_text = list(todos)
    fixmes_text = list(fixmes)
    assert "TODO: Completar secci√≥n" in todos_text
    assert "FIXME: Revisar formato" in fixmes_text


# ---------- EDGE CASES PY ----------
def test_comments_edge_cases_py() -> None:
    text = load_file("edge_cases.py")
    comments = extract_comments(text, language="python")
    assert "Este es un comentario normal" in [c["text"] for c in comments]
    assert "TODO: pendiente de implementar" in [c["text"] for c in comments]
    todos, fixmes = extract_todos_fixmes(comments)
    assert "TODO: pendiente de implementar" in todos


# ---------- DOCSTRING EXAMPLES PY ----------
def test_docstring_examples() -> None:
    text = load_file("docstring_examples.py")
    comments = extract_comments(text, language="python")
    texts = [c["text"] for c in comments]
    # Puede haber o no comentarios; adaptamos a la fixture real
    assert "Comentario entre docstring y c√≥digo" in texts or texts == []
    todos, fixmes = extract_todos_fixmes(comments)
    # Aqu√≠ depende de si hay TODO/FIXME en los comentarios del fichero


# ---------- BASIC MARKDOWN ----------
def test_blank_lines_basic_md() -> None:
    text = load_file("basic.md")
    assert count_blank_lines(text) >= 0


def test_comments_basic_md() -> None:
    text = load_file("basic.md")
    comments = extract_comments(text, language="markdown")
    assert comments == []


# A√±adir tests de regresi√≥n?
def test_comments_edge_cases_py_unicode() -> None:
    text = load_file("edge_cases_comments.py")
    comments = extract_comments(text, language="python")
    texts = [c["text"] for c in comments]
    assert "Este es un comentario con acento: √°√©√≠√≥√∫" in texts
    assert any("üòä" in t for t in texts)
    assert not any(
        t == "# Esto tampoco es comentario" for t in texts
    )  # No debe incluir strings no comentario
    assert any("tarea pendiente Œª" in t for t in texts)
    assert any("Comentario sin espacio tras hash" in t for t in texts)
    assert any("indentaci√≥n" in t for t in texts)
    assert any("s√≠mbolos matem√°ticos" in t for t in texts)
    todos, fixmes = extract_todos_fixmes(comments)
    # Dependiendo de tu extractor, podr√≠as tener que adaptar estos asserts:
    assert any("Œª" in t for t in todos)
    assert any("s√≠mbolos matem√°ticos" in f for f in fixmes)


def test_blank_lines_edge_cases() -> None:
    text = load_file("edge_cases_blanklines.py")
    assert count_blank_lines(text) == 3


def test_comments_edge_cases_md() -> None:
    text = load_file("edge_cases.md")
    comments = extract_comments(text, language="markdown")
    texts = [c["text"] for c in comments]
    assert any("emoji" in t or "üéâ" in t for t in texts)
    assert any("caracteres raros" in t for t in texts)
    assert any("ComentarioSinEspacios" in t for t in texts)


